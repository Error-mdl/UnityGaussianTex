# UnityGaussianTex
Editor utility that transforms a texture to have gaussian histogram and generates lookup table that maps the transformed image back to the original image, for the purpose
of detail preserving blending as described by [Deliot and Heitz (2019)](https://eheitzresearch.wordpress.com/738-2/). The authors of this paper created their own unity plugin available [here](https://github.com/UnityLabs/procedural-stochastic-texturing). The tool presented here was created based soley on the paper, prior to me knowing of the existence of Deliot and Heitz's own unity implementation. Hopefully, this tool still has some value as it is not tied to a particular render pipeline or version of unity, and is implemented very differently using compute shaders for most of the calculations.
# Purpose
In shaders, it is sometimes useful to blend multiple samples of the same texture with different UV coordinates. For example this is done in triplanar mapping, where a texture is sampled three times using flattened world-space coordinates as UVs and the three samples are blended based on normal direction. This is also done in random tiling, where the UVs are divided into a triangular grid. Each grid point has an associated random UV offset, and each pixel blends between three texture samples taken with the offsets of the closest grid points. Doing a simple linear blend produces poor results in many cases, having reduced contrast with details from each texture being washed out and ghostly.

A different solution to blending the texture samples together was first proposed by [Heitz and Neyret (2018)](https://eheitzresearch.wordpress.com/722-2/) and later refined by  Deliot and Heitz (2019). They observed that linear blending does not preserve the statistcal properties of the image, which is expressed by the histogram of the image. However, in the case where the input has a gaussian histogram there exists a different blending formula called a variance-preserving blend which retains the input's histogram. Their solution is to transform the input image's histogram to be gaussian using the inverse cumulative distribution function and to create a lookup table which maps the values in the gaussian-transformed texture back to the colors in the original image. Shaders using these textures first blend samples of the gaussian texture using the variance-preserving formula and then obtain the true color from the lookup table. This produces dramatically better results at the cost of only three (or four if alpha is needed) extra texture samples from the lookup table and a few other operations.
# Details
This script was based almost entirely off of Deliot and Heitz (2019), with a few minor adjustments from the Burley (2019) implementation.
The first step performed by the script is optionally computing a new color-space for the image where each axis is independent, and converting the image to this new colorspace. When blending a gaussian texture derived from normal RGB images, it is possible to generate colors that never existed in the original input as the RGB colors may be correlated. To generate a colorspace where each axis is independent, the tool calculates the covariance matrix of the input's RGB channels and finds its eigenvectors. For simplicity, alpha is not included and assumed to be independent. The eigenvectors are calculated using the iterative formula for 3x3 symmetric, real matricies described by [Eberly (2021)](https://www.geometrictools.com/Documentation/RobustEigenSymmetric3x3.pdf). The new color space is constructed using the eigenvectors as the basis vectors. The space is then shifted so that it is centered on the minimum value of each axis in the image, and the basis vectors are scaled to the bounds of the images values so that all values are in the 0 to 1 range. This step of creating a de-correlated space is optional as not all images will obviously show false colors when blended, and my implementation seems to slightly reduce color accuracy (possibly due to compression issues or loss of precision during the creation of the gaussian texture?).
The next step is to sort each color channel of the image. This is accomplished by a compute shader first splitting each color channel of the input into four compute buffers and generating four identical compute buffers that map the array index to flattened pixel coordinates. These four buffers will be sorted with each color channel, and are used to keep track of the original coordinates of each pixel. Then, each channel is sorted by a compute shader using the bitonic merge sort algorithm. This shader was written following [this tutorial by tgfrerer](https://poniesandlight.co.uk/reflect/bitonic_merge_sort/).
The final step is the actual generation of the gaussian transformed texture and associated lookup table. For each element of each sorted color channel, a compute shader calculates the inverse cumulative distribution function of the element's index divided by the total number of elements and stores the color in the output gaussian image at the coordinates stored in the associated index buffer. Computing the inverse cumulative distribution function is not trivial, as it involves the inverse error function. This function is properly calculated by an infinite series that converges incredibly slowly for values close to 1. Methods which very accurately approximate the inverse error function in fewer steps usually involve complex tricks ill-suited to gpu computation. Rather than actually calculate the inverse error function proper, I have opted to use the approximation described Vedder (1987) which uses a function composed a few sinh and tanh functions. This approximation is massively simpler to compute and is close enough for our purposes to the true value on the 0-1 range. Calculating the lookup table similar, and involves calculating the cumulative distribution function of a value U ranging from 0 to 1, finding the colors stored in the each of the four color channels at the index equal to value of the CDF times the total number of elements, and storing it in the output lookup table at a flattened coordinate equal to U. An array of lookup tables is then made corresponding to each mip level of the input, with each level being a copy of the first table, but treated as a 1d arrray and gaussian blurred.